{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   Escuela Politécnica Nacional  \n",
    "## Ingeniería de Ciencias de la Computación   \n",
    "##  Métodos Numéricos   \n",
    "### Web Scraping\n",
    "### Aubertin Ochoa    \n",
    "### 04/01/2024    \n",
    "     \n",
    "[Link GITHUB](https://github.com/auber-8a/Metodos_Numericos/blob/d4a4c9246327ca89aa15691f24e48cb400746095/webScraping.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping\n",
    "Inicialmente, el desarrollador del scraper analiza el texto fuente en HTML de una página web. Encuentra patrones claros que permiten extraer la información deseada. El scraper se programa para identificar dichos patrones y realiza el resto del trabajo automáticamente.\n",
    "1.\tAbrir la página web a través del URL.\n",
    "2.\tExtraer automáticamente los datos estructurados a partir de los patrones.\n",
    "3.\tResumir, almacenar, evaluar o combinar los datos extraídos, entre otras acciones.\n",
    "\n",
    "## Python para web scraping\n",
    "Puesto que las páginas web han de ser constantemente modificadas, actualizadas, sus contenidos cambian con el tiempo. Puede que cambie su diseño o añadir nuevos elementos. Los webs scrapers se desarrollan teniendo en cuenta la estructura específica de una página web, si esta estructura cambia, el scraper también debe modificarse. Este proceso resulta especialmente sencillo con Python.\n",
    "\n",
    "Como puntos fuertes en Python es el procesamiento de texto y la apertura de recursos web. Además, Python es un consolidado en materia de análisis y procesamiento de datos. Ofrece un amplísimo ecosistema de programación, bibliotecas, documentación, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Realizar una prueba en python para dos librerías diferentes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Realizar scraping de un sitio web de su elección**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Web Scraping Tutorial\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.geeksforgeeks.org/python-web-scraping-tutorial/\"\n",
    "\n",
    "respuesta = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(respuesta.text, 'html.parser')\n",
    "\n",
    "titulos = soup.find_all('h1')\n",
    "for titulo in titulos:\n",
    "    print(titulo.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realiza una petición acerca del título de la página web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "navegador = webdriver.Chrome()\n",
    "\n",
    "navegador.get(\"https://www.geeksforgeeks.org/python-web-scraping-tutorial/\")\n",
    "\n",
    "navegador.save_screenshot(\"captura.png\")\n",
    "\n",
    "navegador.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta petición permite tomar captura de la página web. Esto es útil en procesos automatizados, cuando se necesita verificar si es que todos los datos están cargando correctamente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
